{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import directories\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_blink(df_blink, clf, add_num, levels=5, num_frames=6):\n",
    "    \n",
    "    # === For the amount of added frames before the blink detection, ===\n",
    "    # === add a mirror image to the end of the dataframe             ===\n",
    "    #df_blink_reverse = df_blink.iloc[:add_num].iloc[::-1]\n",
    "    #df_blink_extended = pd.concat([df_blink, df_blink_reverse]).reset_index(drop=True)\n",
    "    df_blink_extended = df_blink.copy()\n",
    "    \n",
    "    # === Reduce data: save only strides of four samples ===\n",
    "    zero_start = 2\n",
    "    zero_end = len(df_blink_extended.index) - 2\n",
    "    \n",
    "    if (zero_end - zero_start > 4):\n",
    "        df_blink_offset = df_blink_extended.drop(df_blink_extended.index[zero_start + 4 : zero_end + 1]).reset_index(drop=True)\n",
    "    else:\n",
    "        df_blink_offset = df_blink_extended.copy()\n",
    "        \n",
    "    # === Add features from neighboring frames ===\n",
    "    features = ['ear','poly']\n",
    "    \n",
    "    for offset in range(num_frames*(-1), num_frames+1):\n",
    "        \n",
    "        # Do something only if the offset isn't zero\n",
    "        if(offset == 0):\n",
    "            continue\n",
    "        \n",
    "        for i in range(len(df_blink_offset.index)):\n",
    "                # Add a column for each selected feature\n",
    "                for feature in features:\n",
    "                    new_column = feature + '_' + str(offset)\n",
    "                    if (i + offset < 0) or (i + offset > len(df_blink_offset.index) - 1):\n",
    "                        df_blink_offset.loc[i, new_column] = 1\n",
    "                    else:\n",
    "                        if np.isnan(df_blink_offset.loc[i + offset, feature]):\n",
    "                            df_blink_offset.loc[i, new_column]  = 1\n",
    "                        else:\n",
    "                            df_blink_offset.loc[i, new_column]  = df_blink_offset.loc[i + offset, feature]\n",
    "        \n",
    "        df_blink_offset.loc[:,'palsy_eye'] = np.ones(len(df_blink_offset.index))\n",
    "        \n",
    "    # === Create X test vector ===\n",
    "    # Add the new columns to the feature list\n",
    "    new_features = []\n",
    "    \n",
    "    for feature in features:\n",
    "        add_cols   = [col for col in df_blink_offset.columns if col.startswith(feature)]\n",
    "        new_features = new_features + add_cols\n",
    "    new_features.append('palsy_eye')\n",
    "    \n",
    "    Xtest = df_blink_offset[new_features]\n",
    "\n",
    "    # === Classify the data using the given classifier ===\n",
    "    y_pred = clf.predict(Xtest)\n",
    "    df_blink_offset.loc[:,'prediction'] = y_pred / (levels - 1)\n",
    "    \n",
    "    print(df_blink_offset[['ear','poly','label','prediction']])\n",
    "    \n",
    "    # === Find the minimum predicted label and consider it as 'blink score' ===\n",
    "    min_pred  = min(df_blink_offset.iloc[1:-1,:]['prediction'])\n",
    "    min_pred_idx = df_blink_offset.loc[df_blink_offset['prediction'] == min_pred].index\n",
    "    min_pred_mid = min_pred_idx[min(len(min_pred_idx) - 1, round(len(min_pred_idx)/2))]\n",
    "    min_locs = df_blink_offset.loc[min_pred_mid-1:min_pred_mid+1,:]['prediction'].reset_index(drop=True)\n",
    "    \n",
    "    if len(min_locs) > 2:\n",
    "            if (min_pred == 0.5 and min_locs[0] == 0.75 and min_locs[2] == 0.75):\n",
    "                min_pred_final = min_pred\n",
    "            elif (min_pred == 0 and min_locs[0] == 0.75 and min_locs[2] == 1):\n",
    "                min_pred_final = min_pred\n",
    "            elif (min_pred == 0 and min_locs[0] == 0.25 and min_locs[2] == 0.5):\n",
    "                min_pred_final = min_pred\n",
    "            elif (min_pred == 0.25 and min_locs[0] == 1 and min_locs[2] == 0.75):\n",
    "                min_pred_final = min_pred\n",
    "            else:\n",
    "                min_pred_final = np.median(min_locs)\n",
    "    \n",
    "    elif (min_pred == 0.5 and min_locs[0] == 0.5 and df_blink_offset.iloc[-1,:]['prediction'] == 0.5):\n",
    "                min_pred_final = 0.75\n",
    "    else:\n",
    "        min_pred_final = np.median(min_locs)\n",
    "    \n",
    "    return min_pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= BLINK NUMBER 1: =======\n",
      "LABEL:  0.25\n",
      "    ear  poly  label  prediction\n",
      "0  0.58  0.46   0.75        1.00\n",
      "1  0.45  0.38   0.75        0.75\n",
      "2  0.19  0.19   0.50        0.75\n",
      "3  0.06  0.08   0.25        0.50\n",
      "4  0.04  0.10   0.25        0.50\n",
      "5  0.13  0.14   0.25        0.75\n",
      "6  0.48  0.45   0.75        1.00\n",
      "CLASSIFICATION:  0.5\n",
      "======= BLINK NUMBER 2: =======\n",
      "LABEL:  0.25\n",
      "    ear  poly  label  prediction\n",
      "0  0.63  0.62   1.00        1.00\n",
      "1  0.63  0.62   1.00        0.75\n",
      "2  0.20  0.25   0.50        0.50\n",
      "3  0.11  0.05   0.25        0.50\n",
      "4  0.00  0.00   0.25        0.50\n",
      "5  0.02  0.06   0.25        0.50\n",
      "6  0.64  0.56   1.00        1.00\n",
      "CLASSIFICATION:  0.5\n",
      "======= BLINK NUMBER 3: =======\n",
      "LABEL:  0.25\n",
      "    ear  poly  label  prediction\n",
      "0  0.76  0.67   0.75        1.00\n",
      "1  0.34  0.26   0.50        0.50\n",
      "2  0.17  0.11   0.25        0.50\n",
      "3  0.26  0.20   0.50        0.50\n",
      "4  0.21  0.15   0.50        0.75\n",
      "5  0.41  0.37   0.75        0.75\n",
      "6  0.75  0.60   1.00        1.00\n",
      "CLASSIFICATION:  0.5\n"
     ]
    }
   ],
   "source": [
    "file_name = 'palsy_18_r_30fps'\n",
    "palsy_loc = 'right'\n",
    "log_name = file_name + \"_log.txt\"\n",
    "blink_buffer = 4\n",
    "blink_consec = 2\n",
    "\n",
    "log_file = open(\"../5_final_product/files/\"+file_name+\"/\"+log_name, 'r')\n",
    "\n",
    "i = 1\n",
    "\n",
    "df_db_xlsx = pd.ExcelFile(\"files/database.xlsx\")\n",
    "df_db = pd.read_excel(df_db_xlsx,'database')\n",
    "\n",
    "clf = load('model.joblib')\n",
    "\n",
    "for line in log_file:\n",
    "    line_split = line.split(' ')\n",
    "    blink_range = line_split[3].split(',')\n",
    "    first_frame = int(blink_range[0][1:]) - (blink_buffer - blink_consec)\n",
    "    last_frame = int(blink_range[1][:-2]) + (blink_buffer - blink_consec)\n",
    "    \n",
    "    print('======= BLINK NUMBER ' + str(i) + \": =======\")\n",
    "    blink_xlsx = pd.ExcelFile(\"../5_final_product/files/\"+file_name+\"/\"+file_name+\"_blink_\"+str(i)+\".xlsx\")\n",
    "    df_blink = pd.read_excel(blink_xlsx,'palsy_eye')\n",
    "    \n",
    "    # Cut the first blink_consec frames\n",
    "    df_blink = df_blink.drop(df_blink.index[:blink_consec]).reset_index(drop=True)\n",
    "    \n",
    "    array = list(range(first_frame, last_frame+1))\n",
    "    #array = list(range(55,62))\n",
    "    df_blink.loc[:,'label'] = df_db.loc[(df_db['video_name'] == file_name) & (df_db['eye_location'] == palsy_loc)\n",
    "                                          & (df_db['frame_number'].isin(array))].reset_index(drop=True).loc[:,'label']\n",
    "    #df_blink = df_db.loc[(df_db['video_name'] == file_name) & (df_db['eye_location'] == palsy_loc)\n",
    "    #                                      & (df_db['frame_number'].isin(array))].reset_index(drop=True)[['ear','poly','palsy_eye','label']]\n",
    "    \n",
    "    #df_blink = df_blink.drop('palsy', axis=1)\n",
    "    df_blink.fillna(1, inplace=True)\n",
    "    #print(df_blink)\n",
    "    \n",
    "    print(\"LABEL: \", min(df_blink.loc[:,'label']))\n",
    "    print(\"CLASSIFICATION: \", classify_blink(df_blink, clf, blink_buffer))\n",
    "    #print (df_db.loc[(df_db['video_name'] == file_name) & (df_db['eye_location'] == palsy_loc)\n",
    "    #                                      & (df_db['frame_number'].isin(array))].reset_index(drop=True).loc[:,'label'])\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
